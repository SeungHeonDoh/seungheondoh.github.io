(this.webpackJsonpseungheondoh=this.webpackJsonpseungheondoh||[]).push([[0],{15:function(e){e.exports=JSON.parse('[{"title":"Enriching Music Descriptions with a Finetuned-LLM and Metadata for Text-to-Music Retrieval","category":"ann_ret nlp","year":"2024","Authors":"SeungHeon Doh, Minhee Lee, Dasaem Jeong, Juhan Nam","bookTitle":"Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2024","bookCategory":"Conferences and Workshops","material":{"demo":"https://seungheondoh.github.io/music-text-representation-pp-demo/"}},{"title":"LP-MusicCaps: LLM-based Pseudo Music Captioning","category":"ann_ret nlp","year":"2023","Authors":"Seungheon Doh, Keunwoo Choi, Jongpil Lee, Juhan Nam","bookTitle":"Proceedings of the 24nd International Society for Music Information Retrieval Conference (ISMIR), 2023","bookCategory":"Conferences and Workshops","material":{"pdf":"https://arxiv.org/abs/2307.16372","code":"https://github.com/seungheondoh/lp-music-caps","dataset":"https://huggingface.co/papers/2307.16372","demo":"https://huggingface.co/spaces/seungheondoh/LP-Music-Caps-demo"}},{"title":"Toward Universal Text-to-Music Retrieval","category":"ann_ret nlp","year":"2023","Authors":"SeungHeon Doh, Minz Won, Keunwoo Choi, Juhan Nam","bookTitle":"Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2023","bookCategory":"Conferences and Workshops","material":{"pdf":"https://arxiv.org/abs/2211.14558","code":"https://github.com/seungheondoh/music-text-representation","demo":"https://seungheondoh.github.io/text-music-representation-demo/","dataset":"https://github.com/SeungHeonDoh/msd-subsets/"}},{"title":"Textless Speech-to-Music Retrieval Using Emotion Similarity","category":"ann_ret audio","year":"2023","Authors":"SeungHeon Doh, Minz Won, Keunwoo Choi, Juhan Nam","bookTitle":"Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2023","bookCategory":"Conferences and Workshops","material":{"pdf":"https://arxiv.org/abs/2303.10539","demo":"https://seungheondoh.github.io/speech-to-music-demo/"}},{"title":"EMOPIA: A Multi-Modal Pop Piano Dataset For Emotion Recognition and Emotion-based Music Generation","category":"ann_ret gen","year":"2021","Authors":"Hung, Hsiao-Tzu and Ching, Joann and Doh, SeungHeon and Kim, Nabin and Nam, Juhan and Yang, Yi-Hsuan","bookTitle":"Proceedings of the 22nd International Society for Music Information Retrieval Conference (ISMIR), 2021","bookCategory":"Conferences and Workshops","material":{"pdf":"https://arxiv.org/abs/2108.01374","demo":"https://annahung31.github.io/EMOPIA//"}},{"title":"Tr\xe4umerAI: Dreaming Music with StyleGAN","category":"gen cv","year":"2021","Authors":"Dasaem Jeong, SeungHeon Doh, and Taegyun Kwon","bookTitle":"Workshop on Machine Learning for Creativity and Design, Neural Information Processing Systems (NeurIPS), 2020","bookCategory":"Conferences and Workshops","material":{"pdf":"https://arxiv.org/abs/2102.04680","demo":"https://jdasam.github.io/traeumerAI_demo/"}},{"title":"Musical Word Embedding: Bridging the Gap between Listening Contexts and Music","category":"ann_ret nlp","year":"2020","Authors":"SeungHeon Doh, Jongpil Lee, Tae Hong Park, and Juhan Nam","bookTitle":"Machine Learning for Media Discovery Workshop, International Conference on Machine Learning (ICML), 2020","bookCategory":"Conferences and Workshops","material":{"pdf":"https://arxiv.org/abs/2008.01190","demo":"https://seungheondoh.github.io/MusicWordVec"}}]')},16:function(e){e.exports=JSON.parse('[{"_id":"enrich2024doh","title":"TTMR++: Enriching Music Descriptions with a Finetuned-LLM and Metadata","decs":"This paper proposes an improved Text-to-Music Retrieval model, denoted as TTMR++, which utilizes rich text descriptions generated with a finetuned large language model and metadata.","category":"research","url":"https://seungheondoh.github.io/music-text-representation-pp-demo/","year":"2024"},{"_id":"lp2023doh","title":"LP-MusicCaps: LLM-Based Pseudo Music Captioning","decs":"We propose the use of large language models (LLMs) to artificially generate the description sentences from large-scale tag datasets. This results in approximately 2.2M captions paired with 0.5M audio clips. We trained a transformer-based music captioning model.","category":"research","url":"https://github.com/seungheondoh/lp-music-caps/","year":"2023"},{"_id":"toward2023doh","title":"Toward Universal Text-to-Music Retrieval","decs":"This paper introduces effective design choices for text-to-music retrieval systems. An ideal text-based retrieval system would support various input queries such as pre-defined tags, unseen tags, and sentence-level descriptions.","category":"research","url":"https://seungheondoh.github.io/text-music-representation-demo/","year":"2023"},{"_id":"speech2023doh","title":"Speech to Music through Emotion","decs":"Automatic speech emotion recognition (SER) can be used as a music recommendation application for content creators. In this paper, our goal is to help creators find music to match the emotion of their speech.","category":"research","url":"https://seungheondoh.github.io/speech-to-music-demo/","year":"2023"},{"_id":"musical_word_embedding","title":"Musical Word Embedding for Music Annotation and Retrieval","decs":"Musical Word Embedding use a wide spectrum of text corpus from general to music-specific words and defining musical specificity of the corpus as a measure of how the semantics of words is specific to the songs or far from it.","category":"research","url":"https://seungheondoh.github.io/musical_word_embedding_demo/","year":"2022"}]')},25:function(e){e.exports=JSON.parse('[{"id":1,"title":"Seungheon Doh","describtion":"I\'m a Ph.D Student at Music and Audio Computing Lab, working on Music, ML/DL.","detail":"I\'m working on Music and Machine Learning, with a specific focus on advancing our understanding of machines\' ability to perceive music, articulate musical experiences using natural language, and generate visual representations. My primary research efforts are concentrated on advancing the domain of representation learning for music and multimodal media","img":"Seungheon_Doh.jpg","ko_name":"\ub3c4\uc2b9\ud5cc","en_name":"Seungheon Doh","material":{"google scholar":"https://scholar.google.com/citations?user=MCkggcgAAAAJ&hl","github":"https://github.com/seungheondoh","linkedin":"https://www.linkedin.com/in/dohppak/","twitter":"https://twitter.com/SeungHeon_Doh"}}]')},26:function(e){e.exports=JSON.parse('[{"date":"Jan-2024","contents":"I\'m starting a research internship at Chartmetric. Collaborate with Keunwoo Choi and Sung Cho","link":"https://chartmetric.com/"},{"date":"Dec-2023","contents":"One paper has been accepted to ICASSP 2024 (Proceedings)","link":""},{"date":"Dec-2023","contents":"One paper has been accepted to IEEE/ACM Transactions on Audio Speech and Language Processing (TASLP)","link":""},{"date":"Dec-2022","contents":"I\'m starting a research internship at NaverCorp (Now AI Team). Collaborate with Jeong Choi","link":"https://scholar.google.co.kr/citations?user=0r1yuiMAAAAJ&hl=ko"},{"date":"May-2022","contents":"As a visiting ph.D student, I will visit the NYU Data Science Center. Collaborate with Prof. Kyunghyun Cho.","link":"https://kyunghyuncho.me/"},{"date":"Jul-2021","contents":"I\'m starting a research internship at ByteDance (Speech, Audio, and Music Intelligence Team). Collaborate with Keunwoo Choi, and MinzWon","link":"https://keunwoochoi.github.io/"}]')},27:function(e){e.exports=JSON.parse('[{"id":"1","title":"All","filter":"*"},{"id":"2","title":"Annotation and Retrieval","filter":"ann_ret"},{"id":"3","title":"Generation","filter":"gen"},{"id":"4","title":"Language & Music","filter":"nlp"},{"id":"5","title":"Vision & Music","filter":"cv"},{"id":"6","title":"Audio & Music","filter":"audio"}]')},28:function(e){e.exports=JSON.parse('{"Teaching":[{"date":"Mar-2023","contents":"TA, GCT731 Topics in Music Technology: Generative AI for Music, KAIST GSCT","link":""},{"date":"Sep-2022","contents":"TA, GCT634 Musical Applications of Machine Learning, KAIST GSCT","link":""},{"date":"Sep-2021","contents":"TA, GCT634 Musical Applications of Machine Learning, KAIST GSCT","link":""},{"date":"Sep-2020","contents":"TA, GCT731 Topics in Music Technology: Cognitive Science of Music, KAIST GSCT","link":""},{"date":"Sep-2019","contents":"TA, GCT576 Social Computing, KAIST GSCT","link":""}],"Talk":[{"date":"Mar-2023","contents":"Multimodal Music Retrieval for Listener and Contents Creator, Seoul Univ. MARG","link":""},{"date":"Dec-2022","contents":"Music Informational Retrieval with Natural Language Processing, YONSEI Univ.","link":""},{"date":"May-2020","contents":"Digital Signal Processing and Speech Recognition, SK planet","link":"https://www.youtube.com/watch?v=RxbkEjV7c0o&t=111s"},{"date":"Aug-2019","contents":"Pycon Tutorial: Music and Deep Learning, PyconKR","link":"https://github.com/Dohppak/Pycon_Tutorial_Music_DeepLearing"}],"Service":[{"date":"Sep-2020","contents":"Korean translator, NYU Deep Learning DS-GA 1008, Yann LeCun & Alfredo Canziani","link":"https://github.com/Atcold/pytorch-Deep-Learning"}]}')},29:function(e){e.exports=JSON.parse('[{"id":"1","school":"Korea Advanced Institute of Science and Technology (KAIST)","position":"Ph.D Student in Graduate School of Culture Technology","duration":"2021 - present","advisor":"@ Music and Audio Computing Lab (Advisor: Juhan Nam)"},{"id":"2","school":"Korea Advanced Institute of Science and Technology (KAIST)","position":"MSc. in Graduate School of Culture Technology","duration":"2019 - 2021","advisor":"@ Music and Audio Computing Lab (Advisor: Juhan Nam)","thesis":"Musical Word Embedding for Natural Language based Music Annotation and Retrieval"},{"id":"3","school":"Ulsan National Institute of Science and Technology (UNIST)","position":"B.S. in School of Business administration & Industrial Design","duration":"2014 - 2019"}]')},30:function(e){e.exports=JSON.parse('[{"id":"1","institution":"Chartmetric","location":"Remote","position":"Research Intern in Audio Analysis Team","duration":"Dec 2023 - Feb 2023","advisor":" (Advisor: Keunwoo Choi)"},{"id":"2","institution":"NaverCorp","location":"1784, South Korea","position":"Research Intern in Now AI Team","duration":"Dec 2022 - Feb 2023","advisor":" (Advisor: Jeong Choi)"},{"id":"3","institution":"Computational Intelligence, Vision, and Robotics Lab (CILVR)","location":"Center for Data Science, New York University, United States","position":"Visiting Student","duration":"Jun 2022 - Aug 2022","advisor":" (Advisor: Kyunghyun Cho)"},{"id":"4","institution":"ByteDance","location":"Remote (due to COVID-19)","position":"Research Intern in Speech, Audio & Music Intelligence Team","duration":"Jul 2021 - Jan 2022","advisor":" (Advisor: Keunwoo Choi, Minz Won)"},{"id":"5","institution":"Music and Audio Research Laboratory (MARL)","location":"Steinhardt, New York University, United States","position":"Visiting Student","duration":"Dec 2019 - Feb 2020","advisor":"(Advisor: TaeHong Park)"}]')},31:function(e){e.exports=JSON.parse('[{"id":"1","title":"All","filter":"*"},{"id":"2","title":"Review","filter":"review"},{"id":"3","title":"Research","filter":"research"}]')},55:function(e,t,n){},56:function(e,t,n){"use strict";n.r(t);var i=n(1),a=n.n(i),o=n(14),s=n.n(o),c=n(32),r=n(2),l=n(8),d=n.n(l),h=n(0);var m=()=>{const e=window.location.href.split("https://seungheondoh.github.io/");return Object(h.jsx)("header",{id:"header",className:"site-header",children:Object(h.jsxs)("div",{className:"wrapper d-flex justify-content-between",children:[Object(h.jsx)("div",{className:"align-self-center",children:Object(h.jsx)("p",{children:"  "})}),Object(h.jsx)("nav",{className:"menu-third",children:Object(h.jsxs)("ul",{className:"clearfix list-unstyled",children:[Object(h.jsx)("li",{className:"menu-item"+("#/"===e[1]?" current-menu-item":""),children:Object(h.jsx)("a",{title:"Home",className:"btn btn-link transform-scale-h border-0 p-0",href:"#/",children:"Home"})}),Object(h.jsx)("li",{className:"menu-item"+("#/blog"===e[1]?" current-menu-item":""),children:Object(h.jsx)("a",{title:"blog",className:"btn btn-link transform-scale-h border-0 p-0",href:"#/blog",children:"Blog"})})]})})]})})};var u=()=>Object(h.jsx)("footer",{id:"footer",className:"site-footer",children:Object(h.jsx)("div",{className:"wrapper no-space",children:Object(h.jsx)("div",{className:"row"})})});var b=e=>{let{keyword:t,link:n,position:i,textcolor:a,backgroundcolor:o}=e;const s="btn ".concat(i," has-text-color ").concat(a," has-background ").concat(o);return Object(h.jsx)("a",{href:n,className:s,children:Object(h.jsx)("b",{children:t})})};var j=e=>{let{keyword:t,link:n,position:i,textcolor:a,backgroundcolor:o}=e;const s="btn ".concat(i," has-text-color ").concat(a," has-background ").concat(o);return Object(h.jsx)("a",{href:n,download:"CV_seunghenodoh",className:s,children:Object(h.jsx)("b",{children:t})})};var g=e=>{let{ProfData:t}=e;return Object(h.jsx)("section",{id:"page-content",className:"spacer",children:Object(h.jsx)("div",{className:"peoplecard",children:Object(h.jsx)("div",{className:"wrapper",children:Object(h.jsx)("div",{className:"prof_cardwrapper",children:t.map((e=>Object(h.jsxs)("div",{className:"img_div",children:[Object(h.jsx)("img",{className:"prof_img",src:"/assets/img/people/"+e.img,alt:e.title}),Object(h.jsxs)("div",{className:"info_div",children:[Object(h.jsx)("h4",{children:e.title}),Object(h.jsxs)("p",{className:"p",children:[" I'm a Ph.D Student at ",Object(h.jsx)("a",{href:"https://mac.kaist.ac.kr/",children:"Music and Audio Computing Lab"}),", advised by ",Object(h.jsx)("a",{href:"https://mac.kaist.ac.kr/~juhan/",children:"Prof. Juhan Nam"}),". ",Object(h.jsx)("br",{}),"My research focuses on the machine's ability to listen to music, express music experience in natural language, and imagine visuals. A key aspect of my research lies in representation learning, particularly in bridging the gap between music and multi-modal media. Presently, my primary focus is on ",Object(h.jsx)("b",{children:"multi-turn conversation"})," and ",Object(h.jsx)("b",{children:"multi-modality"}),". I aim for machines to comprehend diverse modalities during conversations, particularly in the context of music generation and retrieval, facilitating the discovery of music through dialogue."]}),Object(h.jsxs)("div",{className:"btn_div",children:[Object(h.jsx)(j,{keyword:"cv",link:"/assets/cv/CV_seungheon.pdf",position:"",textcolor:"has-white-color",backgroundcolor:"has-olive-background-color"}),Object.keys(e.material).map(((t,n)=>Object(h.jsx)(b,{keyword:t,link:e.material[t],position:"inline",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"})))]})]})]})))})})})})},p=n(25);var x=e=>{let{NewsInfoData:t}=e;return Object(h.jsx)("section",{id:"page-content",className:"spacer p-top-lg p-bottom-lg",children:Object(h.jsx)("div",{id:"blog",children:Object(h.jsxs)("div",{className:"news wrapper",children:[Object(h.jsx)("h4",{children:"News"}),Object(h.jsx)("ul",{children:t.map((e=>""===e.link?Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("li",{children:[" ",e.date," | ",e.contents]})}):Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("li",{children:[" ",e.date," | ",e.contents,Object(h.jsx)(b,{keyword:"Link",link:e.link,position:"inline",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"})]})})))}),Object(h.jsx)("hr",{})]})})})},O=n(26),v=n(12),f=n.n(v),k=n(27),w=n(15);class y extends i.Component{constructor(e){super(e),this.onFilterChange=e=>{const t=this.grid;void 0===this.iso&&(this.iso=new f.a(t,{itemSelector:".publicationTable-item",masonry:{horizontalOrder:!0}})),"*"===e?this.iso.arrange({filter:"*"}):this.iso.arrange({filter:".".concat(e)})},this.onFilterChange=this.onFilterChange.bind(this),this.state={selected:0,list:k}}handleClick(e,t){return t.preventDefault(),this.setState({selected:e}),!1}componentDidMount(){}render(){const e=this.state.list.length-1;return Object(h.jsx)("div",{className:"publicationTable spacer p-bottom-lg",children:Object(h.jsxs)("div",{className:"wrapper",children:[Object(h.jsx)("h4",{children:"Selected Publications"}),Object(h.jsx)("ul",{className:"publicationTable-filter",children:this.state.list.map(((t,n)=>Object(h.jsxs)(a.a.Fragment,{children:[Object(h.jsx)("li",{children:Object(h.jsx)("span",{title:t.title,className:"btn btn-link transform-scale-h click"+(n===this.state.selected?" active":""),"data-filter":t.filter,onClick:e=>{this.onFilterChange(t.filter),this.handleClick(n,e)},children:t.title})}),n!==e?Object(h.jsx)("li",{children:Object(h.jsx)("span",{className:"btn btn-link",children:"-"})}):""]},n)))}),Object(h.jsxs)("div",{className:"publicationTable-item-wrapper",children:[Object(h.jsx)("div",{className:"publicationTable-items",ref:e=>this.grid=e,children:w&&w.map(((e,t)=>""===e.material?Object(h.jsxs)("div",{title:e.title,className:"publicationTable-item active "+e.category,children:[Object(h.jsx)("h6",{children:e.title}),Object(h.jsx)("p",{className:"no-line-hight",children:e.Authors}),Object(h.jsx)("p",{className:"date",children:e.bookTitle})]},t):Object(h.jsxs)("div",{title:e.title,className:"publicationTable-item active "+e.category,children:[Object(h.jsx)("h6",{children:e.title}),Object(h.jsx)("p",{className:"no-line-hight",children:e.Authors}),Object(h.jsx)("p",{className:"date",children:e.bookTitle}),Object.keys(e.material).map(((t,n)=>0===n?Object(h.jsx)(b,{keyword:t,link:e.material[t],position:"",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"}):Object(h.jsx)(b,{keyword:t,link:e.material[t],position:"inline",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"})))]},t)))}),Object(h.jsxs)("h6",{className:"margin",children:["More Publication @ ",Object(h.jsx)("a",{className:"active-color",href:"https://scholar.google.com/citations?user=MCkggcgAAAAJ&hl=en",children:" Google Scholar"})," Page"]})]})]})})}}var S=y;var N=e=>{let{ExpInfoData:t}=e;const n=t.Service,i=t.Talk,a=t.Teaching;return Object(h.jsx)("section",{id:"page-content",className:"spacer p-bottom-lg",children:Object(h.jsx)("div",{id:"blog",children:Object(h.jsxs)("div",{className:"wrapper",children:[Object(h.jsx)("h4",{children:"Service, Talk, Teaching"}),Object(h.jsxs)("div",{className:"experience",children:[Object(h.jsx)("h6",{children:"Service"}),n.map((e=>""===e.link?Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("p",{children:[" ",e.date," | ",e.contents]})}):Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("p",{children:[" ",e.date," | ",e.contents,Object(h.jsx)(b,{keyword:"Link",link:e.link,position:"inline",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"})]})}))),Object(h.jsx)("h6",{children:"Talk"}),i.map((e=>""===e.link?Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("p",{children:[" ",e.date," | ",e.contents]})}):Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("p",{children:[" ",e.date," | ",e.contents,Object(h.jsx)(b,{keyword:"Link",link:e.link,position:"inline",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"})]})}))),Object(h.jsx)("h6",{children:"Teaching"}),a.map((e=>""===e.link?Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("p",{children:[" ",e.date," | ",e.contents]})}):Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("p",{children:[" ",e.date," | ",e.contents,Object(h.jsx)(b,{keyword:"Link",link:e.link,position:"inline",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"})]})})))]})]})})})},C=n(28);var M=e=>{let{EduInfoData:t}=e;return Object(h.jsx)("section",{id:"page-content",className:"spacer p-bottom-lg",children:Object(h.jsx)("div",{id:"blog",children:Object(h.jsxs)("div",{className:"eduacation wrapper",children:[Object(h.jsx)("h4",{children:"Education"}),Object(h.jsx)("div",{className:"eduacation",children:t.map((e=>Object(h.jsxs)(h.Fragment,{children:[Object(h.jsx)("h6",{children:e.school}),Object(h.jsxs)("p",{children:[e.position," ",""!==e.advisor?Object(h.jsx)("p",{children:e.advisor}):null]}),Object(h.jsx)("p",{className:"date",children:e.duration})]})))})]})})})},T=n(29);var A=e=>{let{IndInfoData:t}=e;return Object(h.jsx)("section",{id:"page-content",className:"spacer p-bottom-lg",children:Object(h.jsx)("div",{id:"blog",children:Object(h.jsxs)("div",{className:"industry wrapper",children:[Object(h.jsx)("h4",{children:"Experience"}),Object(h.jsx)("div",{className:"eduacation",children:t.map((e=>Object(h.jsxs)(h.Fragment,{children:[Object(h.jsx)("h6",{children:e.institution}),Object(h.jsxs)("p",{children:[e.position," ",""!==e.advisor?Object(h.jsx)("span",{children:e.advisor}):null]}),Object(h.jsxs)("p",{className:"date",children:[e.location," | ",e.duration]})]})))})]})})})},I=n(30);var D=()=>(document.body.classList.add("home"),document.body.classList.add("bg-fixed"),document.body.classList.add("bg-line"),Object(h.jsxs)(i.Fragment,{children:[Object(h.jsxs)(d.a,{children:[Object(h.jsx)("meta",{charSet:"UTF-8"}),Object(h.jsx)("title",{children:"SeungHeon Doh | MIR, ML/DL Researcher"}),Object(h.jsx)("link",{rel:"icon",href:"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>\ud83c\udfb9</text></svg>"}),Object(h.jsx)("meta",{httpEquiv:"x-ua-compatible",content:"ie=edge"}),Object(h.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),Object(h.jsx)("meta",{name:"description",content:"audio, mir, musical informational retrieval"}),Object(h.jsx)("meta",{name:"keywords",content:"audio, mir, musical informational retrieval"}),Object(h.jsx)("meta",{name:"robots",content:"index, follow, noodp"}),Object(h.jsx)("meta",{name:"googlebot",content:"index, follow"}),Object(h.jsx)("meta",{name:"google",content:"notranslate"}),Object(h.jsx)("meta",{name:"format-detection",content:"telephone=no"})]}),Object(h.jsx)(m,{}),Object(h.jsxs)("main",{id:"main",className:"site-main",children:[Object(h.jsx)(g,{ProfData:p}),Object(h.jsx)(x,{NewsInfoData:O}),Object(h.jsx)(S,{}),Object(h.jsx)(A,{IndInfoData:I}),Object(h.jsx)(M,{EduInfoData:T}),Object(h.jsx)(N,{ExpInfoData:C})]}),Object(h.jsx)(u,{})]})),L=n(31),P=n(16);var R=e=>{let{item:t,key:n}=e;return Object(h.jsx)("section",{title:t.title,className:"blogTable-item active "+t.category,children:Object(h.jsxs)("div",{className:"contents_div",children:[Object(h.jsx)("a",{href:t.url,cursor:"pointer",children:Object(h.jsx)("img",{className:"img_div",src:"/assets/blog/"+t._id+"/thumbnail.png",alt:t._id})}),Object(h.jsxs)("div",{className:"info_div",children:[Object(h.jsxs)("div",{children:[Object(h.jsx)("h5",{children:Object(h.jsx)("a",{href:t.url,cursor:"pointer",children:t.title})}),Object(h.jsx)("p",{className:"desc",children:t.decs})]}),Object(h.jsx)("div",{className:"date_div",children:Object(h.jsx)("p",{className:"blogdate",children:t.year})})]})]})},n)};class E extends i.Component{constructor(e){super(e),this.onFilterChange=e=>{const t=this.grid;void 0===this.iso&&(this.iso=new f.a(t,{itemSelector:".blogTable-item",masonry:{horizontalOrder:!0}})),"*"===e?this.iso.arrange({filter:"*"}):this.iso.arrange({filter:".".concat(e)})},this.onFilterChange=this.onFilterChange.bind(this),this.state={selected:0,list:L}}handleClick(e,t){return t.preventDefault(),this.setState({selected:e}),!1}componentDidMount(){}render(){const e=this.state.list.length-1;return Object(h.jsx)("div",{className:"blogTable spacer p-bottom-lg",children:Object(h.jsxs)("div",{className:"blogTable-wrapper",children:[Object(h.jsx)("h3",{children:"Blogs"}),Object(h.jsx)("ul",{className:"blogTable-filter",children:this.state.list.map(((t,n)=>Object(h.jsxs)(a.a.Fragment,{children:[Object(h.jsx)("li",{children:Object(h.jsx)("span",{title:t.title,className:"btn btn-link transform-scale-h click"+(n===this.state.selected?" active":""),"data-filter":t.filter,onClick:e=>{this.onFilterChange(t.filter),this.handleClick(n,e)},children:t.title})}),n!==e?Object(h.jsx)("li",{children:Object(h.jsx)("span",{className:"btn btn-link",children:"-"})}):""]},n)))}),Object(h.jsx)("div",{className:"blogTable-item-wrapper",children:Object(h.jsx)("div",{className:"blogTable-items",ref:e=>this.grid=e,children:P&&P.map(((e,t)=>(e.material,Object(h.jsx)(R,{item:e},t))))})})]})})}}var _=E;var J=()=>(document.body.classList.add("blog"),document.body.classList.add("bg-fixed"),document.body.classList.add("bg-line"),Object(h.jsxs)(i.Fragment,{children:[Object(h.jsxs)(d.a,{children:[Object(h.jsx)("meta",{charSet:"UTF-8"}),Object(h.jsx)("title",{children:"SeungHeon Doh | MIR Researcher, ML/DL Engineer"}),Object(h.jsx)("link",{rel:"icon",href:"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>\ud83c\udfb9</text></svg>"}),Object(h.jsx)("meta",{httpEquiv:"x-ua-compatible",content:"ie=edge"}),Object(h.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),Object(h.jsx)("meta",{name:"description",content:""}),Object(h.jsx)("meta",{name:"keywords",content:""}),Object(h.jsx)("meta",{name:"robots",content:"index, follow, noodp"}),Object(h.jsx)("meta",{name:"googlebot",content:"index, follow"}),Object(h.jsx)("meta",{name:"google",content:"notranslate"}),Object(h.jsx)("meta",{name:"format-detection",content:"telephone=no"})]}),Object(h.jsx)(m,{}),Object(h.jsx)("main",{id:"main",className:"site-main",children:Object(h.jsx)("div",{className:"wrapper",children:Object(h.jsx)(_,{})})}),Object(h.jsx)(u,{})]}));var F=()=>(document.body.classList.add("thesis"),document.body.classList.add("bg-fixed"),document.body.classList.add("bg-line"),Object(h.jsxs)(i.Fragment,{children:[Object(h.jsxs)(d.a,{children:[Object(h.jsx)("meta",{charSet:"UTF-8"}),Object(h.jsx)("title",{children:"SeungHeon Doh | MIR, ML/DL Researcher"}),Object(h.jsx)("link",{rel:"icon",href:"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>\ud83c\udfb9</text></svg>"}),Object(h.jsx)("meta",{httpEquiv:"x-ua-compatible",content:"ie=edge"}),Object(h.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),Object(h.jsx)("meta",{name:"description",content:""}),Object(h.jsx)("meta",{name:"keywords",content:""}),Object(h.jsx)("meta",{name:"robots",content:"index, follow, noodp"}),Object(h.jsx)("meta",{name:"googlebot",content:"index, follow"}),Object(h.jsx)("meta",{name:"google",content:"notranslate"}),Object(h.jsx)("meta",{name:"format-detection",content:"telephone=no"})]}),Object(h.jsx)(m,{}),Object(h.jsx)("main",{id:"main",className:"site-main",children:Object(h.jsx)("div",{className:"wrapper",children:Object(h.jsx)("p",{children:"Comming Soon"})})}),Object(h.jsx)(u,{})]}));var K=function(){return Object(h.jsxs)(c.a,{basename:"",children:[Object(h.jsx)(r.b,{exact:!0,path:"/",component:D}),Object(h.jsx)(r.b,{path:"/blog",component:J}),Object(h.jsx)(r.b,{path:"/thesis",component:F}),Object(h.jsx)(r.a,{to:"/"})]})};n(55);Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));s.a.render(Object(h.jsx)(K,{}),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((e=>{e.unregister()})).catch((e=>{console.error(e.message)}))}},[[56,1,2]]]);
//# sourceMappingURL=main.c71d637a.chunk.js.map