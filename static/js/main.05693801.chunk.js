(this.webpackJsonpseungheondoh=this.webpackJsonpseungheondoh||[]).push([[0],{22:function(e){e.exports=JSON.parse('[{"title":"Million Song Search: Web Interface for Semantic Music Search Using Musical Word Embedding","category":"ann_ret nlp","year":"2021","Authors":"Seungheon Doh, Jongpil Lee, and Juhan Nam","bookTitle":"Late Breaking Demo in the 22st International Society for Music Information Retrieval Conference (ISMIR), 2021","bookCategory":"Conferences and Workshops","material":{"pdf":"https://archives.ismir.net/ismir2021/latebreaking/000053.pdf","demo":"http://millionsongsearch.kaist.ac.kr/"}},{"title":"Music Playlist Title Generation: A Machine-Translation Approach","category":"gen nlp","year":"2021","Authors":"Seungheon Doh, Junwon Lee, and Juhan Nam","bookTitle":"2nd Workshop on Natural Language Processing for Music and Spoken Audio (NLP4MusA), 2021 (accepted)","bookCategory":"Conferences and Workshops","material":{"pdf":"https://arxiv.org/abs/2110.07354"}},{"title":"EMOPIA: A Multi-Modal Pop Piano Dataset For Emotion Recognition and Emotion-based Music Generation","category":"ann_ret gen","year":"2021","Authors":"Hung, Hsiao-Tzu and Ching, Joann and Doh, Seungheon and Kim, Nabin and Nam, Juhan and Yang, Yi-Hsuan","bookTitle":"Proceedings of the 22nd International Society for Music Information Retrieval Conference (ISMIR), 2021 (accepted)","bookCategory":"Conferences and Workshops","material":{"pdf":"https://arxiv.org/abs/2108.01374","demo":"https://annahung31.github.io/EMOPIA//"}},{"title":"Tr\xe4umerAI: Dreaming Music with StyleGAN","category":"gen cv","year":"2021","Authors":"Dasaem Jeong, Seungheon Doh, and Taegyun Kwon","bookTitle":"Workshop on Machine Learning for Creativity and Design, Neural Information Processing Systems (NeurIPS), 2020","bookCategory":"Conferences and Workshops","material":{"pdf":"https://arxiv.org/abs/2102.04680","demo":"https://jdasam.github.io/traeumerAI_demo/"}},{"title":"Musical Word Embedding: Bridging the Gap between Listening Contexts and Music","category":"ann_ret nlp","year":"2020","Authors":"Seungheon Doh, Jongpil Lee, Tae Hong Park, and Juhan Nam","bookTitle":"Machine Learning for Media Discovery Workshop, International Conference on Machine Learning (ICML), 2020","bookCategory":"Conferences and Workshops","material":{"pdf":"https://arxiv.org/abs/2008.01190","demo":"https://seungheondoh.github.io/MusicWordVec"}}]')},23:function(e){e.exports=JSON.parse('[{"_id":"speech_to_music","title":"Speech to Music through Emotion","decs":"Automatic speech emotion recognition (SER) can be used as a music recommendation application for content creators. In this paper, our goal is to help creators find music to match the emotion of their speech.","category":"research","year":"2022"}]')},32:function(e){e.exports=JSON.parse('[{"id":1,"title":"Seungheon Doh | \ub3c4\uc2b9\ud5cc","describtion":"I\'m a Ph.D Student at Music and Audio Computing Lab, working on Music, ML/DL.","detail":"In particular, my research interests focus on bridging the gap between music and multimedia: multimodal music annotation retrieval (e.g., query by language and vision data) and multimedia generation (e.g., music to image, music to sentence)","img":"Seungheon_Doh.jpg","ko_name":"\ub3c4\uc2b9\ud5cc","en_name":"Seungheon Doh","material":{"google scholar":"https://scholar.google.com/citations?user=MCkggcgAAAAJ&hl","github":"https://github.com/seungheondoh","linkedin":"https://www.linkedin.com/in/dohppak/","twitter":"https://twitter.com/SeungHeonDoh"}}]')},33:function(e){e.exports=JSON.parse('[{"date":"Nov-2021","contents":"Million Song Search papers have been accepted to ISMIR 2021 LBD Session","link":""},{"date":"Sep-2021","contents":"Music Playlist Title Generation papers have been accepted to NLP4Musa 2021!","link":""},{"date":"Jul-2021","contents":"EMOPIA papers have been accepted to ISMIR2021!","link":""},{"date":"Jul-2021","contents":"I\'m starting a research internship at ByteDance (Speech, Audio, and Music Intelligence Team)","link":""}]')},36:function(e){e.exports=JSON.parse('[{"id":"1","title":"All","filter":"*"},{"id":"2","title":"Annotation and Retrieval","filter":"ann_ret"},{"id":"3","title":"Generation","filter":"gen"},{"id":"4","title":"Language & Music","filter":"nlp"},{"id":"5","title":"Vision & Music","filter":"cv"}]')},37:function(e){e.exports=JSON.parse('{"Teaching":[{"date":"Sep-2021","contents":"TA, GCT634 Musical Applications of Machine Learning, KAIST GSCT","link":""},{"date":"Sep-2020","contents":"TA, GCT731 Topics in Music Technology: Cognitive Science of Music, KAIST GSCT","link":""},{"date":"Sep-2019","contents":"TA, GCT576 Social Computing, KAIST GSCT","link":""}],"Talk":[{"date":"May-2020","contents":"Digital Signal Processing and Speech Recognition, SK planet","link":"https://www.youtube.com/watch?v=RxbkEjV7c0o&t=111s"},{"date":"Aug-2019","contents":"Pycon Tutorial: Music and Deep Learning, PyconKR","link":"https://github.com/Dohppak/Pycon_Tutorial_Music_DeepLearing"}],"Experience":[{"date":"Sep-2020","contents":"Korean translator, NYU Deep Learning DS-GA 1008, Yann LeCun & Alfredo Canziani","link":"https://github.com/Atcold/pytorch-Deep-Learning"},{"date":"Feb-2020","contents":"Visiting Student, Music and Audio Research Laboratory, New York University, United States","link":""}]}')},38:function(e){e.exports=JSON.parse('[{"id":"1","school":"Korea Advanced Institute of Science and Technology (KAIST)","position":"Ph.D Student in Graduate School of Culture Technology","duration":"2021 - present","advisor":"@ Music and Audio Computing Lab (Advisor: Juhan Nam)"},{"id":"2","school":"Korea Advanced Institute of Science and Technology (KAIST)","position":"MSc. in Graduate School of Culture Technology","duration":"2019 - 2021","advisor":"@ Music and Audio Computing Lab (Advisor: Juhan Nam)","thesis":"Musical Word Embedding for Natural Language based Music Annotation and Retrieval"},{"id":"3","school":"Ulsan National Institute of Science and Technology (UNIST)","position":"B.S. in School of Business administration & Industrial Design","duration":"2014 - 2019"}]')},39:function(e){e.exports=JSON.parse('[{"id":"1","institution":"ByteDance","location":"Mountain View, United States","position":"Research Intern in Speech, Audio & Music Intelligence Team","duration":"Jul 2021 - Jan 2022","advisor":" (Advisor: Keunwoo Choi, Minz Won)"}]')},40:function(e){e.exports=JSON.parse('[{"id":"1","title":"All","filter":"*"},{"id":"2","title":"Review","filter":"review"},{"id":"3","title":"Research","filter":"research"}]')},64:function(e,t,n){},65:function(e,t,n){"use strict";n.r(t);var s=n(1),i=n.n(s),a=n(20),c=n.n(a),o=n(41),r=n(2),l=n(7),d=n.n(l),h=n(0),j=function(){var e=window.location.href.split("https://seungheondoh.github.io/");return Object(h.jsx)("header",{id:"header",className:"site-header",children:Object(h.jsxs)("div",{className:"wrapper d-flex justify-content-between",children:[Object(h.jsx)("div",{className:"align-self-center",children:Object(h.jsx)("p",{children:"  "})}),Object(h.jsx)("nav",{className:"menu-third",children:Object(h.jsxs)("ul",{className:"clearfix list-unstyled",children:[Object(h.jsx)("li",{className:"menu-item"+("#/"===e[1]?" current-menu-item":""),children:Object(h.jsx)("a",{title:"Home",className:"btn btn-link transform-scale-h border-0 p-0",href:"#/",children:"Home"})}),Object(h.jsx)("li",{className:"menu-item"+("#/blog"===e[1]?" current-menu-item":""),children:Object(h.jsx)("a",{title:"blog",className:"btn btn-link transform-scale-h border-0 p-0",href:"#/blog",children:"Blog"})})]})})]})})},b=function(){return Object(h.jsx)("footer",{id:"footer",className:"site-footer",children:Object(h.jsx)("div",{className:"wrapper no-space",children:Object(h.jsx)("div",{className:"row"})})})},m=function(e){var t=e.keyword,n=e.link,s=e.position,i=e.textcolor,a=e.backgroundcolor,c="btn ".concat(s," has-text-color ").concat(i," has-background ").concat(a);return Object(h.jsx)("a",{href:n,className:c,children:Object(h.jsx)("b",{children:t})})},u=function(e){var t=e.keyword,n=e.link,s=e.position,i=e.textcolor,a=e.backgroundcolor,c="btn ".concat(s," has-text-color ").concat(i," has-background ").concat(a);return Object(h.jsx)("a",{href:n,download:"CV_seunghenodoh",className:c,children:Object(h.jsx)("b",{children:t})})},p=function(e){var t=e.ProfData;return Object(h.jsx)("section",{id:"page-content",className:"spacer",children:Object(h.jsx)("div",{className:"peoplecard",children:Object(h.jsx)("div",{className:"wrapper",children:Object(h.jsx)("div",{className:"prof_cardwrapper",children:t.map((function(e){return Object(h.jsxs)("div",{className:"img_div",children:[Object(h.jsx)("img",{className:"prof_img",src:"/assets/img/people/"+e.img,alt:e.title}),Object(h.jsxs)("div",{className:"info_div",children:[Object(h.jsx)("h4",{children:e.title}),Object(h.jsxs)("p",{children:[e.describtion," ",Object(h.jsx)("br",{})," ",e.detail]}),Object(h.jsxs)("div",{className:"btn_div",children:[Object(h.jsx)(u,{keyword:"cv",link:"/assets/cv/CV_seungheon(20211114).pdf",position:"",textcolor:"has-white-color",backgroundcolor:"has-orange-background-color"}),Object.keys(e.material).map((function(t,n){return Object(h.jsx)(m,{keyword:t,link:e.material[t],position:"inline",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"})}))]})]})]})}))})})})})},g=n(32),x=function(e){var t=e.NewsInfoData;return Object(h.jsx)("section",{id:"page-content",className:"spacer p-top-lg p-bottom-lg",children:Object(h.jsx)("div",{id:"blog",children:Object(h.jsxs)("div",{className:"news wrapper",children:[Object(h.jsx)("h4",{children:"News"}),Object(h.jsx)("ul",{children:t.map((function(e){return""===e.link?Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("li",{children:[" ",e.date," | ",e.contents]})}):Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("li",{children:[e.date,", ",Object(h.jsx)("a",{href:e.link,children:"[Link]"})]})})}))}),Object(h.jsx)("hr",{})]})})})},O=n(33),f=n(14),y=n(15),v=n(9),w=n(16),k=n(18),N=n(17),S=n.n(N),_=n(36),M=n(22),T=function(e){Object(w.a)(n,e);var t=Object(k.a)(n);function n(e){var s;return Object(f.a)(this,n),(s=t.call(this,e)).onFilterChange=function(e){var t=s.grid;void 0===s.iso&&(s.iso=new S.a(t,{itemSelector:".publicationTable-item",masonry:{horizontalOrder:!0}})),"*"===e?s.iso.arrange({filter:"*"}):s.iso.arrange({filter:".".concat(e)})},s.onFilterChange=s.onFilterChange.bind(Object(v.a)(s)),s.state={selected:0,list:_},s}return Object(y.a)(n,[{key:"handleClick",value:function(e,t){return t.preventDefault(),this.setState({selected:e}),!1}},{key:"componentDidMount",value:function(){}},{key:"render",value:function(){var e=this,t=this.state.list.length-1;return Object(h.jsx)("div",{className:"publicationTable spacer p-bottom-lg",children:Object(h.jsxs)("div",{className:"wrapper",children:[Object(h.jsx)("h4",{children:"Publications"}),Object(h.jsx)("ul",{className:"publicationTable-filter",children:this.state.list.map((function(n,s){return Object(h.jsxs)(i.a.Fragment,{children:[Object(h.jsx)("li",{children:Object(h.jsx)("span",{title:n.title,className:"btn btn-link transform-scale-h click"+(s===e.state.selected?" active":""),"data-filter":n.filter,onClick:function(t){e.onFilterChange(n.filter),e.handleClick(s,t)},children:n.title})}),s!==t?Object(h.jsx)("li",{children:Object(h.jsx)("span",{className:"btn btn-link",children:"-"})}):""]},s)}))}),Object(h.jsx)("div",{className:"publicationTable-item-wrapper",children:Object(h.jsx)("div",{className:"publicationTable-items",ref:function(t){return e.grid=t},children:M&&M.map((function(e,t){return""===e.material?Object(h.jsxs)("div",{title:e.title,className:"publicationTable-item active "+e.category,children:[Object(h.jsx)("h6",{children:e.title}),Object(h.jsx)("p",{children:e.Authors}),Object(h.jsx)("p",{className:"date",children:e.bookTitle})]},t):Object(h.jsxs)("div",{title:e.title,className:"publicationTable-item active "+e.category,children:[Object(h.jsx)("h6",{children:e.title}),Object(h.jsx)("p",{children:e.Authors}),Object(h.jsx)("p",{className:"date",children:e.bookTitle}),Object.keys(e.material).map((function(t,n){return 0===n?Object(h.jsx)(m,{keyword:t,link:e.material[t],position:"",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"}):Object(h.jsx)(m,{keyword:t,link:e.material[t],position:"inline",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"})}))]},t)}))})})]})})}}]),n}(s.Component),I=function(e){var t=e.ExpInfoData,n=t.Experience,s=t.Talk,i=t.Teaching;return Object(h.jsx)("section",{id:"page-content",className:"spacer p-bottom-lg",children:Object(h.jsx)("div",{id:"blog",children:Object(h.jsxs)("div",{className:"wrapper",children:[Object(h.jsx)("h4",{children:"Experience, Talk, Teaching"}),Object(h.jsxs)("div",{className:"experience",children:[Object(h.jsx)("h6",{children:"Experience"}),n.map((function(e){return""===e.link?Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("p",{children:[" ",e.date," | ",e.contents]})}):Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("p",{children:[" ",e.date," | ",e.contents,Object(h.jsx)(m,{keyword:"Link",link:e.link,position:"inline",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"})]})})})),Object(h.jsx)("h6",{children:"Talk"}),s.map((function(e){return""===e.link?Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("p",{children:[" ",e.date," | ",e.contents]})}):Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("p",{children:[" ",e.date," | ",e.contents,Object(h.jsx)(m,{keyword:"Link",link:e.link,position:"inline",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"})]})})})),Object(h.jsx)("h6",{children:"Teaching"}),i.map((function(e){return""===e.link?Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("p",{children:[" ",e.date," | ",e.contents]})}):Object(h.jsx)(h.Fragment,{children:Object(h.jsxs)("p",{children:[" ",e.date," | ",e.contents,Object(h.jsx)(m,{keyword:"Link",link:e.link,position:"inline",textcolor:"has-white-color",backgroundcolor:"has-gray-dark-background-color"})]})})}))]})]})})})},A=n(37),C=function(e){var t=e.EduInfoData;return Object(h.jsx)("section",{id:"page-content",className:"spacer p-bottom-lg",children:Object(h.jsx)("div",{id:"blog",children:Object(h.jsxs)("div",{className:"eduacation wrapper",children:[Object(h.jsx)("h4",{children:"Education"}),Object(h.jsx)("div",{className:"eduacation",children:t.map((function(e){return Object(h.jsxs)(h.Fragment,{children:[Object(h.jsx)("h6",{children:e.school}),Object(h.jsxs)("p",{children:[e.position," ",""!==e.advisor?Object(h.jsx)("p",{children:e.advisor}):null]}),Object(h.jsx)("p",{className:"date",children:e.duration})]})}))})]})})})},D=n(38),L=function(e){var t=e.IndInfoData;return Object(h.jsx)("section",{id:"page-content",className:"spacer p-bottom-lg",children:Object(h.jsx)("div",{id:"blog",children:Object(h.jsxs)("div",{className:"industry wrapper",children:[Object(h.jsx)("h4",{children:"Industry Experience"}),Object(h.jsx)("div",{className:"eduacation",children:t.map((function(e){return Object(h.jsxs)(h.Fragment,{children:[Object(h.jsx)("h6",{children:e.institution}),Object(h.jsxs)("p",{children:[e.position," ",""!==e.advisor?Object(h.jsx)("span",{children:e.advisor}):null]}),Object(h.jsxs)("p",{className:"date",children:[e.location," | ",e.duration]})]})}))})]})})})},F=n(39),E=function(){return document.body.classList.add("home"),document.body.classList.add("bg-fixed"),document.body.classList.add("bg-line"),Object(h.jsxs)(s.Fragment,{children:[Object(h.jsxs)(d.a,{children:[Object(h.jsx)("meta",{charSet:"UTF-8"}),Object(h.jsx)("title",{children:"SeungHeon Doh | MIR, ML/DL Researcher"}),Object(h.jsx)("link",{rel:"icon",href:"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>\ud83c\udfb9</text></svg>"}),Object(h.jsx)("meta",{httpEquiv:"x-ua-compatible",content:"ie=edge"}),Object(h.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),Object(h.jsx)("meta",{name:"description",content:"audio, mir, musical informational retrieval"}),Object(h.jsx)("meta",{name:"keywords",content:"audio, mir, musical informational retrieval"}),Object(h.jsx)("meta",{name:"robots",content:"index, follow, noodp"}),Object(h.jsx)("meta",{name:"googlebot",content:"index, follow"}),Object(h.jsx)("meta",{name:"google",content:"notranslate"}),Object(h.jsx)("meta",{name:"format-detection",content:"telephone=no"})]}),Object(h.jsx)(j,{}),Object(h.jsxs)("main",{id:"main",className:"site-main",children:[Object(h.jsx)(p,{ProfData:g}),Object(h.jsx)(x,{NewsInfoData:O}),Object(h.jsx)(T,{}),Object(h.jsx)(L,{IndInfoData:F}),Object(h.jsx)(C,{EduInfoData:D}),Object(h.jsx)(I,{ExpInfoData:A})]}),Object(h.jsx)(b,{})]})},J=n(40),R=n(23),P=function(e){var t=e.item,n=e.key;return Object(h.jsx)("section",{title:t.title,className:"blogTable-item active "+t.category,children:Object(h.jsxs)("div",{className:"contents_div",children:[Object(h.jsx)("a",{href:"#/"+t._id,cursor:"pointer",children:Object(h.jsx)("img",{className:"img_div",src:"/assets/blog/"+t._id+"/thumbnail.png",alt:t._id})}),Object(h.jsxs)("div",{className:"info_div",children:[Object(h.jsxs)("div",{children:[Object(h.jsx)("h5",{children:Object(h.jsx)("a",{href:"#/"+t._id,cursor:"pointer",children:t.title})}),Object(h.jsx)("p",{className:"desc",children:t.decs})]}),Object(h.jsx)("div",{className:"date_div",children:Object(h.jsx)("p",{className:"blogdate",children:t.year})})]})]})},n)},W=function(e){Object(w.a)(n,e);var t=Object(k.a)(n);function n(e){var s;return Object(f.a)(this,n),(s=t.call(this,e)).onFilterChange=function(e){var t=s.grid;void 0===s.iso&&(s.iso=new S.a(t,{itemSelector:".blogTable-item",masonry:{horizontalOrder:!0}})),"*"===e?s.iso.arrange({filter:"*"}):s.iso.arrange({filter:".".concat(e)})},s.onFilterChange=s.onFilterChange.bind(Object(v.a)(s)),s.state={selected:0,list:J},s}return Object(y.a)(n,[{key:"handleClick",value:function(e,t){return t.preventDefault(),this.setState({selected:e}),!1}},{key:"componentDidMount",value:function(){}},{key:"render",value:function(){var e=this,t=this.state.list.length-1;return Object(h.jsx)("div",{className:"blogTable spacer p-bottom-lg",children:Object(h.jsxs)("div",{className:"blogTable-wrapper",children:[Object(h.jsx)("h3",{children:"Blogs"}),Object(h.jsx)("ul",{className:"blogTable-filter",children:this.state.list.map((function(n,s){return Object(h.jsxs)(i.a.Fragment,{children:[Object(h.jsx)("li",{children:Object(h.jsx)("span",{title:n.title,className:"btn btn-link transform-scale-h click"+(s===e.state.selected?" active":""),"data-filter":n.filter,onClick:function(t){e.onFilterChange(n.filter),e.handleClick(s,t)},children:n.title})}),s!==t?Object(h.jsx)("li",{children:Object(h.jsx)("span",{className:"btn btn-link",children:"-"})}):""]},s)}))}),Object(h.jsx)("div",{className:"blogTable-item-wrapper",children:Object(h.jsx)("div",{className:"blogTable-items",ref:function(t){return e.grid=t},children:R&&R.map((function(e,t){return e.material,Object(h.jsx)(P,{item:e},t)}))})})]})})}}]),n}(s.Component),B=function(){return document.body.classList.add("blog"),document.body.classList.add("bg-fixed"),document.body.classList.add("bg-line"),Object(h.jsxs)(s.Fragment,{children:[Object(h.jsxs)(d.a,{children:[Object(h.jsx)("meta",{charSet:"UTF-8"}),Object(h.jsx)("title",{children:"SeungHeon Doh | MIR Researcher, ML/DL Engineer"}),Object(h.jsx)("link",{rel:"icon",href:"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>\ud83c\udfb9</text></svg>"}),Object(h.jsx)("meta",{httpEquiv:"x-ua-compatible",content:"ie=edge"}),Object(h.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),Object(h.jsx)("meta",{name:"description",content:""}),Object(h.jsx)("meta",{name:"keywords",content:""}),Object(h.jsx)("meta",{name:"robots",content:"index, follow, noodp"}),Object(h.jsx)("meta",{name:"googlebot",content:"index, follow"}),Object(h.jsx)("meta",{name:"google",content:"notranslate"}),Object(h.jsx)("meta",{name:"format-detection",content:"telephone=no"})]}),Object(h.jsx)(j,{}),Object(h.jsx)("main",{id:"main",className:"site-main",children:Object(h.jsx)("div",{className:"wrapper",children:Object(h.jsx)(W,{})})}),Object(h.jsx)(b,{})]})},G=function(){return document.body.classList.add("thesis"),document.body.classList.add("bg-fixed"),document.body.classList.add("bg-line"),Object(h.jsxs)(s.Fragment,{children:[Object(h.jsxs)(d.a,{children:[Object(h.jsx)("meta",{charSet:"UTF-8"}),Object(h.jsx)("title",{children:"SeungHeon Doh | MIR, ML/DL Researcher"}),Object(h.jsx)("link",{rel:"icon",href:"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>\ud83c\udfb9</text></svg>"}),Object(h.jsx)("meta",{httpEquiv:"x-ua-compatible",content:"ie=edge"}),Object(h.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),Object(h.jsx)("meta",{name:"description",content:""}),Object(h.jsx)("meta",{name:"keywords",content:""}),Object(h.jsx)("meta",{name:"robots",content:"index, follow, noodp"}),Object(h.jsx)("meta",{name:"googlebot",content:"index, follow"}),Object(h.jsx)("meta",{name:"google",content:"notranslate"}),Object(h.jsx)("meta",{name:"format-detection",content:"telephone=no"})]}),Object(h.jsx)(j,{}),Object(h.jsx)("main",{id:"main",className:"site-main",children:Object(h.jsx)("div",{className:"wrapper",children:Object(h.jsx)("p",{children:"Comming Soon"})})}),Object(h.jsx)(b,{})]})},K=function(){return document.body.classList.add("blog"),document.body.classList.add("bg-fixed"),document.body.classList.add("bg-line"),Object(h.jsxs)(s.Fragment,{children:[Object(h.jsxs)(d.a,{children:[Object(h.jsx)("meta",{charSet:"UTF-8"}),Object(h.jsx)("title",{children:"SeungHeon Doh | MIR, ML/DL Researcher"}),Object(h.jsx)("link",{rel:"icon",href:"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>\ud83c\udfb9</text></svg>"}),Object(h.jsx)("meta",{httpEquiv:"x-ua-compatible",content:"ie=edge"}),Object(h.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),Object(h.jsx)("meta",{name:"description",content:""}),Object(h.jsx)("meta",{name:"keywords",content:""}),Object(h.jsx)("meta",{name:"robots",content:"index, follow, noodp"}),Object(h.jsx)("meta",{name:"googlebot",content:"index, follow"}),Object(h.jsx)("meta",{name:"google",content:"notranslate"}),Object(h.jsx)("meta",{name:"format-detection",content:"telephone=no"})]}),Object(h.jsx)(j,{}),Object(h.jsx)("main",{id:"main",className:"site-main",children:Object(h.jsxs)("div",{className:"wrapper",children:[Object(h.jsx)("h3",{children:"Speech to Music through Emotion"}),Object(h.jsx)("pre",{children:Object(h.jsx)("code",{children:"Speech to Music through Emotion, Interspeech 2022 - SeungHeon Doh, Minz Won, Keunwoo Choi, Juhan Nam"})}),Object(h.jsxs)("p",{children:["This project maps ",Object(h.jsx)("strong",{children:"speech"})," and ",Object(h.jsx)("strong",{children:"music"})," to the same embedding space and supports music item search for speech query by calculating the similarity between them. The detail of the methodology for building the dataset please refer to our paper."]}),Object(h.jsxs)("ul",{children:[Object(h.jsx)("li",{children:"Paper on Arxiv"}),Object(h.jsx)("li",{children:"Pre-trained model on Zenodo"}),Object(h.jsx)("li",{children:"Implementation Code"})]}),Object(h.jsx)("h4",{children:"Abstract"}),Object(h.jsx)("p",{children:"Automatic speech emotion recognition (SER) can be used as a music recommendation application for content creators. In this paper, our goal is to assist content creators in finding music that matches the emotion of their speech. We focus on a cross-modal speech-to-music retrieval framework to simultaneously perform feature extraction and bridge the modality gap using emotion labels. Moreover, we propose a novel masking fusion method, which obtains the ensemble effect by stochastic modality feature selection. Our experiments show that we can successfully bridge the gap between modalities to facilitate cross-modal retrieval. In addition, comprehensive experimental results compared with four retrieval methods on five speech modality representations verify the effectiveness of our masking fusion method."}),Object(h.jsx)("img",{className:"blog_contents",src:"/assets/blog/speech_to_music/main.png",alt:"speech_to_music"}),Object(h.jsx)("h4",{children:"In the wild demo"}),Object(h.jsxs)("p",{children:["To demonstrate real industrial scenarios, we use samples from social media contents (tiktok #actingscene tag) and audio books contents (youtube). It also searches for music using only the audio modality because it assumes no transcription. It also makes use of the ",Object(h.jsx)("a",{href:"https://www.jyu.fi/hytk/fi/laitokset/mutku/en/research/projects2/past-projects/coe/materials/emotion/soundtracks/Index",children:"soundtrack360 dataset"})," as a high-quality audio database."]}),Object(h.jsx)("iframe",{className:"blog_contents",width:"560",height:"600",src:"https://www.youtube.com/embed/K2Aent-pRnM",title:"YouTube video player",frameborder:"0",allowfullscreen:!0}),Object(h.jsx)("h4",{children:"Test-set demo"}),Object(h.jsxs)("p",{children:[" We report the results for IEMOCAP and Audioset, which are test datsets reported in the paper. The samples below were extracted based on the ",Object(h.jsx)("a",{href:"https://github.com/SeungHeonDoh/speech_to_music/blob/master/notebook/demo.ipynb",children:"code"}),"."]}),Object(h.jsxs)("table",{children:[Object(h.jsxs)("tr",{children:[Object(h.jsx)("th",{children:"  "}),Object(h.jsx)("th",{children:" Speech Query "}),Object(h.jsx)("th",{children:" Similar Music 1 "}),Object(h.jsx)("th",{children:" Similar Music 2 "}),Object(h.jsx)("th",{children:" Similar Music 3 "})]}),Object(h.jsxs)("tr",{children:[Object(h.jsx)("th",{children:" angry "}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/angry/angry.wav",type:"audio/mpeg"})," "]}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/angry/angry (1).wav",type:"audio/mpeg"})," "]}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/angry/angry (2).wav",type:"audio/mpeg"})," "]}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/angry/angry (3).wav",type:"audio/mpeg"})," "]})]}),Object(h.jsxs)("tr",{children:[Object(h.jsx)("th",{children:" happy "}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/happy/happy.wav",type:"audio/mpeg"})," "]}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/happy/happy (1).wav",type:"audio/mpeg"})," "]}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/happy/happy (2).wav",type:"audio/mpeg"})," "]}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/happy/happy (3).wav",type:"audio/mpeg"})," "]})]}),Object(h.jsxs)("tr",{children:[Object(h.jsx)("th",{children:" sad "}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/sad/sad.wav",type:"audio/mpeg"})," "]}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/sad/sad (1).wav",type:"audio/mpeg"})," "]}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/sad/sad (2).wav",type:"audio/mpeg"})," "]}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/sad/sad (3).wav",type:"audio/mpeg"})," "]})]}),Object(h.jsxs)("tr",{children:[Object(h.jsx)("th",{children:" neutral "}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/neutral/neutral.wav",type:"audio/mpeg"})," "]}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/neutral/neutral (1).wav",type:"audio/mpeg"})," "]}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/neutral/neutral (2).wav",type:"audio/mpeg"})," "]}),Object(h.jsxs)("th",{children:[" ",Object(h.jsx)("audio",{controls:!0,id:"player",onplay:"pauseOthers(this);",src:"/assets/blog/speech_to_music/neutral/neutral (3).wav",type:"audio/mpeg"})," "]})]})]}),Object(h.jsx)("h4",{children:"Visualization"}),Object(h.jsx)("p",{children:"First of all, for both the VA embedding space and the metric learning space, emotion labels that share a similar semantic are neighboring together in the embedding. In contrast to VA regression, metric learning discriminates between emotions and noise-neutral. Comparing uni-modal speech representation (Figure-(c),(d),(e),(f)), audio modality shows strong cohesion for each emotion label and has low error variance. Even for incorrect samples, this will lead to high errors. The text modality, on the other hand, has high error variance. It makes that angry and neutral embeddings are mixed up. The late fusion + masking approach (Figure-(g),(h)) shows a more generalized embedding distribution by alleviating the high error problem and mix-up problem between angry and neutral."}),Object(h.jsx)("img",{className:"blog_contents",src:"/assets/blog/speech_to_music/viz.png",alt:"speech_to_music"})]})}),Object(h.jsx)(b,{})]})};var z=function(){return Object(h.jsxs)(o.a,{basename:"",children:[Object(h.jsx)(r.b,{exact:!0,path:"/",component:E}),Object(h.jsx)(r.b,{path:"/blog",component:B}),Object(h.jsx)(r.b,{path:"/speech_to_music",component:K}),Object(h.jsx)(r.b,{path:"/thesis",component:G}),Object(h.jsx)(r.a,{to:"/"})]})};n(64),Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));c.a.render(Object(h.jsx)(z,{}),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()})).catch((function(e){console.error(e.message)}))}},[[65,1,2]]]);
//# sourceMappingURL=main.05693801.chunk.js.map